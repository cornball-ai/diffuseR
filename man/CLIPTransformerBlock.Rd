\name{CLIPTransformerBlock}
\alias{CLIPTransformerBlock}
\title{CLIP Transformer Block}
\description{Pre-norm transformer block with attention and MLP (HuggingFace style)}
\arguments{
  \item{embed_dim}{Embedding dimension}
  \item{num_heads}{Number of attention heads}
  \item{mlp_dim}{MLP hidden dimension}
  \item{gelu_type}{GELU variant: "tanh", "quick", or "exact"}
}
\keyword{internal}
