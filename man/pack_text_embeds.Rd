% Generated by rhydrogen: do not edit by hand
% Please edit documentation in R/text_encoder_ltx2.R
\name{pack_text_embeds}
\alias{pack_text_embeds}
\title{Pack Text Embeddings (Gemma-style)}
\usage{
pack_text_embeds(
  text_hidden_states,
  sequence_lengths,
  padding_side = "left",
  scale_factor = 8,
  eps = 1e-06,
  device = "cpu"
)
}
\arguments{
\item{text_hidden_states}{Tensor of shape [batch, seq_len, hidden_dim, num_layers].}

\item{sequence_lengths}{Integer vector of valid sequence lengths per batch item.}

\item{padding_side}{Character. "left" or "right".}

\item{scale_factor}{Numeric. Scale factor for normalization (default 8).}

\item{eps}{Numeric. Epsilon for numerical stability.}

\item{device}{Character. Device for tensors.}
}
\value{
Tensor of shape [batch, seq_len, hidden_dim * num_layers].
}
\description{
Normalizes and packs text encoder hidden states from multiple layers.
This is used when working with raw Gemma outputs.
}
