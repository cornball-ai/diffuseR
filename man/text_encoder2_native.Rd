% Generated by rhydrogen: do not edit by hand
% Please edit documentation in R/text_encoder.R
\name{text_encoder2_native}
\alias{text_encoder2_native}
\title{Native CLIP Text Encoder 2 (OpenCLIP ViT-bigG for SDXL)}
\arguments{
\item{vocab_size}{Vocabulary size (default 49408)}

\item{context_length}{Maximum sequence length (default 77)}

\item{embed_dim}{Embedding dimension (default 1280)}

\item{num_layers}{Number of transformer layers (default 32)}

\item{num_heads}{Number of attention heads (default 20)}

\item{mlp_dim}{MLP hidden dimension (default 5120)}
}
\value{
An nn_module representing the text encoder
}
\description{
Native R torch implementation of OpenCLIP text encoder used in SDXL.
Returns both hidden states and pooled output.
}
