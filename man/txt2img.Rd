% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/txt2img.R
\name{txt2img}
\alias{txt2img}
\title{Generate an image from a text prompt using a diffusion pipeline}
\usage{
txt2img(
  prompt,
  negative_prompt = NULL,
  img_dim = 512,
  model_name = "stable-diffusion-2-1",
  devices = "cpu",
  unet_dtype_str = NULL,
  scheduler = "ddim",
  timesteps = NULL,
  initial_latents = NULL,
  num_inference_steps = 50,
  guidance_scale = 7.5,
  seed = NULL,
  save_to = "output.png",
  metadata_path = NULL,
  ...
)
}
\arguments{
\item{prompt}{A character string prompt describing the image to generate.}

\item{negative_prompt}{Optional negative prompt to guide the generation.}

\item{img_dim}{Dimension of the output image (e.g., 512 for 512x512).}

\item{model_name}{Name of the model to use (e.g., \code{"stable-diffusion-2-1"}).}

\item{devices}{A named list of devices for each model component (e.g., \code{list(unet = "cuda", decoder = "cpu", text_encoder = "cpu")}).}

\item{scheduler}{Scheduler to use (e.g., \code{"ddim"}, \code{"euler"}).}

\item{timesteps}{Optional A vector of timesteps to use.}

\item{num_inference_steps}{Number of inference steps to run.}

\item{guidance_scale}{Scale for classifier-free guidance (typically 7.5).}

\item{seed}{Optional seed for reproducibility.}

\item{save_to}{Optional file path to save the final image.}

\item{metadata_path}{Optional file path to save metadata.}

\item{...}{Additional parameters passed to the diffusion process.}

\item{unet_dtype}{Optional A character for dtype of the unet component (typically "torch_float16" for cuda and "torch_float32" for cpu).}
}
\value{
A tensor or image object, depending on implementation.
}
\description{
Generate an image from a text prompt using a diffusion pipeline
}
\examples{
\dontrun{
img <- txt2img("a cat wearing sunglasses in space", device = "cuda")
}
}
