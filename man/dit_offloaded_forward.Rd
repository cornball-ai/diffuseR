% Generated by rhydrogen: do not edit by hand
% Please edit documentation in R/gpu_poor.R
\name{dit_offloaded_forward}
\alias{dit_offloaded_forward}
\title{DiT Layer-by-Layer Forward Pass}
\usage{
dit_offloaded_forward(hidden_states, layers, device = "cuda", ...)
}
\arguments{
\item{hidden_states}{Input tensor.}

\item{layers}{List of transformer layers (on CPU).}

\item{device}{Target device for computation.}

\item{...}{Additional arguments passed to each layer.}
}
\value{
Output tensor (on CPU).
}
\description{
Runs transformer layers one at a time, moving each to GPU before
computation and back to CPU after. For extreme memory-constrained
scenarios.
}
\examples{
\dontrun{
# During low-VRAM inference
output <- dit_offloaded_forward(
  hidden_states,
  model$transformer_blocks,
  device = "cuda",
  encoder_hidden_states = text_embeds
)
}
}
