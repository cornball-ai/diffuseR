% Generated by rhydrogen: do not edit by hand
% Please edit documentation in R/gpu_poor.R
\name{dit_offloaded_forward}
\alias{dit_offloaded_forward}
\title{DiT Chunk-based Forward Pass}
\usage{
dit_offloaded_forward(
  hidden_states,
  layers,
  chunk_size = 1L,
  device = "cuda",
  verbose = FALSE,
  ...
)
}
\arguments{
\item{hidden_states}{Input tensor.}

\item{layers}{List of transformer layers (on CPU).}

\item{chunk_size}{Integer. Number of layers to load at once (default 1).}

\item{device}{Target device for computation.}

\item{verbose}{Logical. Print progress.}

\item{...}{Additional arguments passed to each layer.}
}
\value{
Output tensor (on CPU).
}
\description{
Runs transformer layers in chunks, moving each chunk to GPU before
computation and back to CPU after. Balances memory usage with speed.
}
\examples{
\dontrun{
# Layer-by-layer for 8GB VRAM
output <- dit_offloaded_forward(
  hidden_states,
  model$transformer_blocks,
  chunk_size = 1,
  device = "cuda"
)

# Chunk-based for 16GB VRAM
output <- dit_offloaded_forward(
  hidden_states,
  model$transformer_blocks,
  chunk_size = 12,  # 12 layers at a time
  device = "cuda"
)
}
}
