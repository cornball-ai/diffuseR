% Generated by rhydrogen: do not edit by hand
% Please edit documentation in R/text_encoder.R
\name{text_encoder_native}
\alias{text_encoder_native}
\title{Native CLIP Text Encoder}
\arguments{
\item{vocab_size}{Vocabulary size (default 49408)}

\item{context_length}{Maximum sequence length (default 77)}

\item{embed_dim}{Embedding dimension}

\item{num_layers}{Number of transformer layers}

\item{num_heads}{Number of attention heads}

\item{mlp_dim}{MLP hidden dimension}

\item{apply_final_ln}{Whether to apply final layer norm (default TRUE). Set to FALSE to match
TorchScript exports that don't include final LN.}
}
\value{
An nn_module representing the text encoder
}
\description{
Native R torch implementation of CLIP text encoder. Replaces TorchScript
for better GPU compatibility.
}
