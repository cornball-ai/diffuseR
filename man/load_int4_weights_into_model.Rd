% Generated by rhydrogen: do not edit by hand
% Please edit documentation in R/gpu_poor.R
\name{load_int4_weights_into_model}
\alias{load_int4_weights_into_model}
\title{Load INT4 Weights into INT4 Model}
\usage{
load_int4_weights_into_model(model, int4_weights, verbose = TRUE)
}
\arguments{
\item{model}{nn_module created with INT4 layers.}

\item{int4_weights}{List from `load_int4_weights()`.}

\item{verbose}{Logical. Print progress.}
}
\value{
Model with INT4 weights loaded (invisibly).
}
\description{
Loads pre-quantized INT4 weights into a model created with
`make_linear()` when `diffuseR.use_int4 = TRUE`.
}
