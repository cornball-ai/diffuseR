<!-- Generated by fyi::use_fyi_md() on 2026-01-13 -->
<!-- Regenerate with: fyi::use_fyi_md("diffuseR") -->

# fyi: diffuseR

## Exported Functions (diffuseR::)

| Function | Arguments |
|----------|-----------|
| `auto_devices` | model, strategy |
| `CLIPTokenizer` | prompt, merges, vocab_file, pad_token |
| `ddim_scheduler_create` | num_train_timesteps, num_inference_steps, eta, beta_schedule, beta_start, beta_end, rescale_betas_zero_snr, dtype, device |
| `ddim_scheduler_step` | model_output, timestep, sample, schedule, eta, use_clipped_model_output, thresholding, generator, variance_noise, clip_sample, set_alpha_to_one, prediction_type, dtype, device |
| `download_component` | model_name, component, device, overwrite, show_progress |
| `filename_from_prompt` | prompt, datetime |
| `img2img` | input_image, prompt, negative_prompt, img_dim, model_name, pipeline, devices, unet_dtype_str, download_models, scheduler, num_inference_steps, strength, guidance_scale, seed, save_file, filename, metadata_path, use_native_decoder, use_native_text_encoder, use_native_unet, ... |
| `load_decoder_weights` | native_decoder, torchscript_path, verbose |
| `load_model_component` | component, model_name, device, unet_dtype_str, download, use_native |
| `load_pipeline` | model_name, m2d, i2i, unet_dtype_str, use_native_decoder, use_native_text_encoder, use_native_unet, ... |
| `load_text_encoder_weights` | native_encoder, torchscript_path, verbose |
| `load_text_encoder2_weights` | native_encoder, torchscript_path, verbose |
| `load_unet_sdxl_weights` | native_unet, torchscript_path, verbose |
| `load_unet_weights` | native_unet, torchscript_path, verbose |
| `models2devices` | model_name, devices, unet_dtype_str, download_models |
| `post_quant_conv` | x, dtype, device |
| `preprocess_image` | input, device, width, height |
| `quant_conv` | x, dtype, device |
| `save_image` | img, save_to, normalize |
| `scheduler_add_noise` | original_latents, noise, timestep, scheduler_obj |
| `text_encoder_native` | vocab_size, context_length, embed_dim, num_layers, num_heads, mlp_dim, apply_final_ln |
| `text_encoder2_native` | vocab_size, context_length, embed_dim, num_layers, num_heads, mlp_dim |
| `txt2img` | prompt, model_name, ... |
| `txt2img_sd21` | prompt, negative_prompt, img_dim, pipeline, devices, unet_dtype_str, download_models, scheduler, timesteps, initial_latents, num_inference_steps, guidance_scale, seed, save_file, filename, metadata_path, use_native_decoder, use_native_text_encoder, use_native_unet, ... |
| `txt2img_sdxl` | prompt, negative_prompt, img_dim, pipeline, devices, unet_dtype_str, download_models, scheduler, timesteps, initial_latents, num_inference_steps, guidance_scale, seed, save_file, filename, metadata_path, use_native_decoder, use_native_text_encoder, use_native_unet, ... |
| `unet_native` | in_channels, out_channels, block_out_channels, layers_per_block, cross_attention_dim, attention_head_dim |
| `unet_native_from_torchscript` | torchscript_path, verbose |
| `unet_sdxl_native` | in_channels, out_channels, block_out_channels, layers_per_block, transformer_layers_per_block, cross_attention_dim, attention_head_dim, addition_embed_dim, addition_time_embed_dim |
| `unet_sdxl_native_from_torchscript` | torchscript_path, verbose |
| `vae_decoder_native` | latent_channels, out_channels |


## Internal Functions (diffuseR:::)

| Function | Arguments |
|----------|-----------|
| `.build_fallback_devices` | model, strategy |
| `BasicTransformerBlock` | dim, n_heads, d_head, context_dim |
| `CLIPAttention` | embed_dim, num_heads |
| `CLIPMLP` | in_dim, hidden_dim, gelu_type |
| `CLIPTransformerBlock` | embed_dim, num_heads, mlp_dim, gelu_type |
| `detect_text_encoder_architecture` | torchscript_path |
| `detect_unet_architecture` | torchscript_path |
| `detect_unet_sdxl_architecture` | torchscript_path |
| `download_model` | model_name, devices, unet_dtype_str, overwrite, show_progress, download_models |
| `Downsample2D` | channels |
| `FeedForward` | dim, mult |
| `GEGLU` | dim_in, dim_out |
| `get_component_file_path` | component, model_dir, device, unet_dtype_str |
| `get_required_components` | model_name |
| `group_norm_32` | channels |
| `load_text_encoders` | model_name, device, download |
| `quick_gelu` | x |
| `rescale_zero_terminal_snr` | betas |
| `setup_dtype` | devices, unet_dtype_str |
| `SpatialTransformer` | in_channels, n_heads, d_head, depth, context_dim |
| `standardize_devices` | devices, required_components |
| `timestep_embedding` | timesteps, dim, flip_sin_to_cos, downscale_freq_shift |
| `token_get_pairs` | symbols |
| `token_merge_pair_once` | symbols, bigram |
| `UNetCrossAttention` | query_dim, context_dim, heads, dim_head |
| `UNetResBlock` | in_channels, out_channels, time_embed_dim |
| `Upsample2D` | channels |
| `VAEAttentionBlock` | channels |
| `VAEMidBlock` | channels |
| `VAEResnetBlock` | in_channels, out_channels |
| `VAEUpBlock` | in_channels, out_channels, num_resnets, add_upsample |


## Options

No options found in `diffuseR`.



## Documentation Topics (56)

For details, read `man-md/<topic>.md` or use `fyi_help("topic", "pkg")`.

Topics: `auto_devices`, `BasicTransformerBlock`, `CLIPAttention`, `CLIPMLP`, `CLIPTokenizer`, `CLIPTransformerBlock`, `ddim_scheduler_create`, `ddim_scheduler_step`, `detect_text_encoder_architecture`, `detect_unet_architecture`, `detect_unet_sdxl_architecture`, `dot-build_fallback_devices`, `download_component`, `download_model`, `Downsample2D`, `FeedForward`, `filename_from_prompt`, `GEGLU`, `get_required_components`, `group_norm_32`, `img2img`, `load_decoder_weights`, `load_model_component`, `load_pipeline`, `load_text_encoder_weights`, `load_text_encoder2_weights`, `load_unet_sdxl_weights`, `load_unet_weights`, `models2devices`, `post_quant_conv`, `preprocess_image`, `quant_conv`, `quick_gelu`, `save_image`, `scheduler_add_noise`, `setup_dtype`, `SpatialTransformer`, `standardize_devices`, `text_encoder_native`, `text_encoder2_native`, `timestep_embedding`, `txt2img`, `txt2img_sd21`, `txt2img_sdxl`, `unet_native`, `unet_native_from_torchscript`, `unet_sdxl_native`, `unet_sdxl_native_from_torchscript`, `UNetCrossAttention`, `UNetResBlock`, `Upsample2D`, `vae_decoder_native`, `VAEAttentionBlock`, `VAEMidBlock`, `VAEResnetBlock`, `VAEUpBlock`

